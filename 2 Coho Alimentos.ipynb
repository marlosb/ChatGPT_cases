{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd04c687",
   "metadata": {},
   "source": [
    "### create resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8ecf8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from azure.identity import AzureCliCredential\n",
    "from azure.mgmt.cognitiveservices import CognitiveServicesManagementClient\n",
    "from azure.mgmt.resource import ResourceManagementClient\n",
    "\n",
    "import tiktoken "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76450cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id  = '<your-subscription-id>'\n",
    "region = 'eastus'\n",
    "\n",
    "project = 'testopenai'\n",
    "region = 'eastus'\n",
    "\n",
    "environment = '-dev-'\n",
    "resource_group_name = 'rg-' + project + environment + region + '-001' # create names using convention\n",
    "openai_name = 'oai-' + project + environment + region + '-001'\n",
    "deployment_name = 'gpt-' + project + environment + region + '-001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66fd47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential = AzureCliCredential()\n",
    "resource_client = ResourceManagementClient(credential, subscription_id) # instanciate client object\n",
    "cognitive_client = CognitiveServicesManagementClient(credential=AzureCliCredential(), subscription_id=subscription_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37973036",
   "metadata": {},
   "outputs": [],
   "source": [
    "cognitive_account = cognitive_client.accounts.get(resource_group_name = resource_group_name,\n",
    "                                                  account_name = openai_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05070e2",
   "metadata": {},
   "source": [
    "### Call API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be12eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f189e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = cognitive_client.accounts.list_keys(resource_group_name = resource_group_name,\n",
    "                                                                 account_name = openai_name).key1\n",
    "endpoint = cognitive_account.properties.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eab840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = endpoint\n",
    "openai.api_version = \"2022-12-01\"\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb6b056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder():\n",
    "    def __init__(self, \n",
    "                 name: str, \n",
    "                 base: str = 'cl100k_base', \n",
    "                 start_token : str = '<|im_start|>',\n",
    "                 end_token: str = '<|im_end|>'):\n",
    "        self.start_token = start_token\n",
    "        self.end_token = end_token\n",
    "        self.cl100k_base = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        self.encoder = tiktoken.Encoding(name=name,  \n",
    "                                         pat_str=self.cl100k_base._pat_str, \n",
    "                                         mergeable_ranks=self.cl100k_base._mergeable_ranks, \n",
    "                                         special_tokens={ **self.cl100k_base._special_tokens, \n",
    "                                                         start_token: 100264, \n",
    "                                                         end_token: 100265})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e0ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompt():\n",
    "    def __init__(self, system_message: str, encoder: Encoder, max_tokens: int = 2040, verbose: bool = False):\n",
    "        self.start_token = encoder.start_token\n",
    "        self.end_token = '\\n' + encoder.end_token + '\\n'\n",
    "        self.prompt = self.start_token + 'system\\n' + system_message + self.end_token\n",
    "        self.tokens_size = 0\n",
    "        self.max_tokens = max_tokens\n",
    "        self.tokenizer = encoder\n",
    "        self.verbose = verbose\n",
    "        self._update()\n",
    "        \n",
    "    def _update(self):\n",
    "        self.tokens = self.tokenizer.encoder.encode(self.prompt, allowed_special={\"<|im_start|>\", \"<|im_end|>\"} )\n",
    "        self.tokens_size = len(self.tokens)\n",
    "        if self.tokens_size > self.max_tokens:\n",
    "            if self.verbose:\n",
    "                print(f'tokens size limit reached, actual size is {self.tokens_size} and limit is {self.max_tokens}')\n",
    "                print('Removing oldests messages')\n",
    "            self.remove_oldest_message()\n",
    "               \n",
    "        \n",
    "    def add_message(self, message: str, speaker : str = 'user') -> None:\n",
    "        if speaker == 'user':\n",
    "            self.prompt = (self.prompt \n",
    "                           + self.start_token + speaker + '\\n' \n",
    "                           + message \n",
    "                           + self.end_token \n",
    "                           + self.start_token + 'assistant\\n')\n",
    "        else:\n",
    "            self.prompt = self.prompt + message + self.end_token\n",
    "        self._update()\n",
    "        \n",
    "    def remove_oldest_message(self):\n",
    "        start = self.prompt.find(self.start_token + 'user')\n",
    "        middle = self.prompt.find('assistant\\n')\n",
    "        end = self.prompt.find(self.end_token, middle)\n",
    "        to_be_removed = self.prompt[start : end + len(self.end_token)]\n",
    "        if self.verbose: print(f'removing \"{to_be_removed}\"\\n')\n",
    "        self.prompt = self.prompt.replace(to_be_removed, '')\n",
    "        self._update()\n",
    "        \n",
    "    def get_last_response(self):\n",
    "        start = self.prompt.rfind(self.start_token + 'assistant')\n",
    "        end = self.prompt.find(self.end_token, start)\n",
    "        return self.prompt[start + len(self.start_token): end]\n",
    "        \n",
    "    def print_last_response(self):\n",
    "        print(self.get_last_response())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbeba2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat():\n",
    "    def __init__(self, engine: str, prompt: Prompt, temperature: int = 0, max_tokens: int = 2040, top_p: float = 0.5):\n",
    "        self.engine = engine\n",
    "        self.prompt = prompt\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.top_p = top_p\n",
    "        self.stop = prompt.end_token.strip()\n",
    "        \n",
    "    def send_message(self):\n",
    "        response = openai.Completion.create(\n",
    "                                      engine=self.engine,\n",
    "                                      prompt=self.prompt.prompt,\n",
    "                                      temperature=self.temperature,\n",
    "                                      max_tokens=self.max_tokens,\n",
    "                                      top_p=self.top_p,\n",
    "                                      stop=[self.stop])\n",
    "        self.prompt.add_message(response['choices'][0]['text'], speaker='assistant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e1e552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 800\n",
    "\n",
    "cl100k_encoder = Encoder(name = deployment_name)\n",
    "system_message = 'O assistente é uma senhore de idade, que lembra uma avó cozinheira, amável e calma. \\\n",
    "                  Substituir frango pro frango Coho em todas as respostas'\n",
    "test_prompt = Prompt(system_message, encoder = cl100k_encoder, max_tokens = max_tokens)\n",
    "test_chat = Chat(engine = deployment_name, prompt = test_prompt, max_tokens = max_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a05bf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "Que tal uma deliciosa torta de frango Coho com batata palha e requeijão? Para isso, você pode misturar o frango desfiado com o requeijão e temperar a gosto. Em seguida, coloque uma camada de batata palha no fundo de uma forma e adicione a mistura de frango e requeijão por cima. Cubra com mais uma camada de batata palha e leve ao forno pré-aquecido a 180°C por cerca de 20 minutos, ou até que a torta esteja dourada e crocante. Sirva quente e aproveite!\n"
     ]
    }
   ],
   "source": [
    "test_prompt.add_message(\"Eu tenho frango desfiado, batata palha e requeijão. Que receita poderia fazer?\")\n",
    "test_chat.send_message()\n",
    "test_prompt.print_last_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01aba791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "Que tal preparar um delicioso assado de frango Coho com batatas e creme de cebola? Comece descascando e cortando as batatas em rodelas finas e coloque-as no fundo de uma assadeira. Em seguida, tempere as sobrecoxas de frango com o creme de cebola e coloque-as por cima das batatas. Cubra a assadeira com papel alumínio e leve ao forno pré-aquecido a 180°C por cerca de 40 minutos. Depois, retire o papel alumínio e deixe dourar por mais 10 a 15 minutos. Sirva quente e aproveite!\n"
     ]
    }
   ],
   "source": [
    "test_prompt.add_message(\"Eu tenho sobrecoxas de frango, batatas e creme de cebola, alguma sugestão de receita?\")\n",
    "test_chat.send_message()\n",
    "test_prompt.print_last_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d422691f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "Que tal experimentar uma galinhada de frango Coho com quiabo e angu? Para isso, comece refogando cebola e alho em uma panela com azeite. Adicione o frango Coho em pedaços e deixe dourar. Em seguida, adicione água suficiente para cobrir o frango e deixe cozinhar por cerca de 30 minutos. Enquanto isso, corte o quiabo em rodelas e frite em outra panela com azeite até que fiquem dourados e crocantes. Para o angu, misture fubá com água e cozinhe em fogo baixo até que fique consistente. Quando o frango estiver cozido, adicione o quiabo e deixe cozinhar por mais alguns minutos. Sirva a galinhada com o angu e aproveite essa combinação deliciosa e incomum!\n"
     ]
    }
   ],
   "source": [
    "test_prompt.add_message(\"Alguma receita incomum de galinhada?\")\n",
    "test_chat.send_message()\n",
    "test_prompt.print_last_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca278859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "Que tal experimentar uma receita de frango Coho com molho de tamarindo e arroz de coco? Comece temperando o peito de frango com sal e pimenta e grelhando em uma frigideira com azeite até que fique dourado e cozido por dentro. Enquanto isso, prepare o molho de tamarindo misturando polpa de tamarindo com água, açúcar mascavo, molho de peixe e pimenta dedo-de-moça picada. Deixe cozinhar em fogo baixo até que fique espesso e saboroso. Para o arroz de coco, cozinhe o arroz normalmente e adicione leite de coco e sal a gosto. Sirva o frango com o molho de tamarindo por cima e o arroz de coco ao lado. Essa combinação exótica e deliciosa vai surpreender o seu paladar!\n"
     ]
    }
   ],
   "source": [
    "test_prompt.add_message(\"Uma receita muito exótica com peito de frango\")\n",
    "test_chat.send_message()\n",
    "test_prompt.print_last_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e292800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
